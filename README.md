# ml-engine
### C++/LibTorch Training & llama.cpp Inference for macOS M2


[![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Platform](https://img.shields.io/badge/platform-macOS%20M2%20%7C%20Linux%20%7C%20CPU%2FGPU-blue.svg)]()
[![Language](https://img.shields.io/badge/language-C%2B%2B%20%7C%20LibTorch%20%7C%20llama.cpp-orange.svg)]()

<p align="right">
<a href="#13-ë¶€ë¡-ë¹ ë¥¸-ì‹œì‘" style="font-weight:bold;background:#e0f7fa;border-radius:8px;padding:6px 16px;text-decoration:none;">ğŸš€ Quick Start ë°”ë¡œê°€ê¸°</a>
</p>

---

## ê°œìš”

**ml-engine**ì€ C++/LibTorch ê¸°ë°˜ì˜ ëª¨ë¸(Module)ì„ ì§ì ‘ ë¹Œë“œí•´ ë°ì´í„°ì…‹ì˜ lossë¥¼ ìµœì†Œí™”í•˜ëŠ” í•™ìŠµ ì—”ì§„ì´ë©°, ë™ì‹œì— ì™¸ë¶€ ì‹¤í–‰(ì˜ˆ: llama.cpp) ì„ í†µí•´ LLM ì¶”ë¡ ì„ RESTë¡œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ëŠ” ì„œë²„/CLIì…ë‹ˆë‹¤.

- í•™ìŠµ ëŒ€ìƒ: `src/ml/models/...` ì•„ë˜ LibTorch C++ Module í´ë˜ìŠ¤ë§Œ
- ê²€ì¦ ë°ì´í„°ì…‹: MNIST (28Ã—28, í‘ë°±, 0â€“9)
- ì¶”ë¡ : llama.cpp ë°”ì´ë„ˆë¦¬ë¥¼ ì„œë¸Œí”„ë¡œì„¸ìŠ¤ë¡œ í˜¸ì¶œí•˜ì—¬ GGUF ëª¨ë¸ ì‹¤í–‰
- macOS(Apple Silicon): LibTorch Metal í•™ìŠµ ë¯¸ì§€ì› â†’ CPU í•™ìŠµ, llama.cppëŠ” Metal ê°€ì†(-ngl 99) ê°€ëŠ¥
- LLM íŒŒì¸íŠœë‹ì€ PyTorch/Hugging Face + (Q)LoRA ë˜ëŠ” llama.cppì˜ LoRA/QLoRA ê²½ë¡œë¥¼ ì‚¬ìš©
- thirdpartyì˜ libtorchëŠ” ë³¸ í”„ë¡œê·¸ë¨ ë°ëª¨ì˜ ê²½ìš° `libtorch-macos-arm64-2.8.0.zip`ë¥¼ ì‚¬ìš©
- license 
---


## ëª©ì°¨

1. [íŠ¹ì§•](#1-íŠ¹ì§•)
2. [í™˜ê²½ ë° ê¸°ìˆ  ê°œìš”](#2-í™˜ê²½-ë°-ê¸°ìˆ -ê°œìš”)
3. [í”„ë¡œì íŠ¸ êµ¬ì¡°](#3-í”„ë¡œì íŠ¸-êµ¬ì¡°)
4. [ë¹Œë“œ & ì‹¤í–‰](#4-ë¹Œë“œ--ì‹¤í–‰)
5. [REST API](#5-rest-api)
6. [í•™ìŠµ/ì¶”ë¡  ì˜ˆì‹œ](#6-í•™ìŠµì¶”ë¡ -ì˜ˆì‹œ)
7. [ëª¨ë¸ ì¶”ì²œ & ì–‘ìí™” ê°€ì´ë“œ](#7-ëª¨ë¸-ì¶”ì²œ--ì–‘ìí™”-ê°€ì´ë“œ)
8. [ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸](#8-ìš´ì˜-ì²´í¬ë¦¬ìŠ¤íŠ¸)
9. [ë¡œë“œë§µ](#9-ë¡œë“œë§µ)
10. [ìì£¼ ë°œìƒí•˜ëŠ” ì´ìŠˆ](#10-ìì£¼-ë°œìƒí•˜ëŠ”-ì´ìŠˆ)
11. [ìš©ì–´ ì‚¬ì „](#11-ìš©ì–´-ì‚¬ì „)
12. [ë¼ì´ì„ ìŠ¤](#12-ë¼ì´ì„ ìŠ¤)
13. [ë¶€ë¡: ë¹ ë¥¸ ì‹œì‘](#13-ë¶€ë¡-ë¹ ë¥¸-ì‹œì‘)
14. [DeepSeek-Coder-V2-Lite Instruct ì„ íƒ ë° ì‹¤ì „ ë¡œê·¸](#14-deepseek-coder-v2-lite-instruct-ì„ íƒ-ë°-ì‹¤ì „-ë¡œê·¸)
15. [ë¶€ë¡: DeepSeek-Coder-V2-Lite Instruct GGUF ë©”íƒ€ë°ì´í„° ë° ì‹¤í–‰ ë¡œê·¸ í•´ì„¤](#15-ë¶€ë¡-deepseek-coder-v2-lite-instruct-gguf-ë©”íƒ€ë°ì´í„°-ë°-ì‹¤í–‰-ë¡œê·¸-í•´ì„¤)
16. [ë¶€ë¡: ì„œë²„ ê¸°ë™ ë° ë¼ì´ì„ ìŠ¤ ì²´í¬ ë™ì‘](#16-ë¶€ë¡-ì„œë²„-ê¸°ë™-ë°-ë¼ì´ì„ ìŠ¤-ì²´í¬-ë™ì‘)
17. [ì•„í‚¤í…ì²˜ ê³ ë„í™” ë° êµ¬í˜„ ê³„íš(ìì²´ LLM v1 ë¡œë“œë§µ)](#17-ì•„í‚¤í…ì²˜-ê³ ë„í™”-ë°-êµ¬í˜„-ê³„íšìì²´-llm-v1-ë¡œë“œë§µ)
---

## 1. íŠ¹ì§•

- C++/LibTorch í•™ìŠµ ì—”ì§„
- `src/ml/models/...`ì˜ Moduleë§Œ í•™ìŠµ ê°€ëŠ¥ (ì˜ˆ: cnn_mnist)
- seed ê³ ì •, DataLoader shuffle ê³ ì •, cuDNN deterministic ì œì–´(í•´ë‹¹ í™˜ê²½)
- stdout + íŒŒì¼ ë¡œê·¸ ê¸°ë³¸, JSONL/TensorBoard/wandb C++ë¡œ í™•ì¥ ê°€ëŠ¥
- llama.cpp ì—°ë™ LLM ì¶”ë¡  (ì„œë¸Œí”„ë¡œì„¸ìŠ¤, GGUF ëª¨ë¸)
- macOS Metal ê°€ì†(ë¹Œë“œ ì‹œ -DGGML_METAL=ON, ì‹¤í–‰ ì‹œ -ngl 99)
- í”ŒëŸ¬ê·¸ì¸í™”(ì„ íƒ): .so/.dllë¡œ ë¹Œë“œ í›„ ëŸ°íƒ€ì„ êµì²´/ì¶”ê°€(ì´ˆê¸°ì—” ì •ì  ë§í¬ë¡œë„ ì¶©ë¶„)
- ë¶„ì‚°/ë©€í‹°GPU(í™•ì¥): torch::distributed + DDPë¡œ í™•ì¥ ê°€ëŠ¥

---

## 2. í™˜ê²½ ë° ê¸°ìˆ  ê°œìš”

- CUDA(NVIDIA): LibTorch CUDA ë¹Œë“œ ì„¤ì¹˜ ì‹œ GPU í•™ìŠµ ê°€ëŠ¥
- ROCm(AMD): PyTorch ì¼ë¶€ ë²„ì „ ì§€ì›
- CPU: GPU ì—†ê±°ë‚˜ macOS Metal í•™ìŠµ ë¯¸ì§€ì› ì‹œ CPU í•™ìŠµ/ì¶”ë¡ 
- macOS(Apple Silicon): LibTorch Metal í•™ìŠµ ë¯¸ì§€ì›, llama.cppëŠ” Metal ê°€ì†(-ngl 99) ê°€ëŠ¥
- AMP: torch::autocast ì‚¬ìš©, ë©”ëª¨ë¦¬ ì ˆì•½/ì†ë„ í–¥ìƒ
- ë°ì´í„°ì…‹: MNIST, ImageFolderDataset, CSV/Parquet ì»¤ìŠ¤í…€ Dataset
- ë¡œê¹…: ì½˜ì†”/íŒŒì¼ ê¸°ë³¸, JSONL/TensorBoard/wandb í™•ì¥ ê°€ëŠ¥

---

## 3. í”„ë¡œì íŠ¸ êµ¬ì¡°

```text
ml-engine/
â”œâ”€ CMakeLists.txt
â”œâ”€ third_party/
â”‚  â””â”€ libtorch/
â”œâ”€ include/
â”‚  â”œâ”€ log.h
â”‚  â”œâ”€ safe_arithmetic_ops.h
â”‚  â”œâ”€ api/
â”‚  â”‚  â”œâ”€ api_server.hpp
â”‚  â”‚  â””â”€ handler/handler_base.hpp
â”‚  â”œâ”€ engine/
â”‚  â”‚  â”œâ”€ engine.hpp
â”‚  â”‚  â””â”€ engine_state.hpp
â”‚  â””â”€ ml/
â”‚     â”œâ”€ model_base.hpp
â”‚     â”œâ”€ registry.hpp
â”‚     â”œâ”€ trainer.hpp
â”‚     â””â”€ dataset.hpp
â”œâ”€ src/
â”‚  â”œâ”€ main.cpp
â”‚  â”œâ”€ api/
â”‚  â”‚  â”œâ”€ api_server.cpp
â”‚  â”‚  â””â”€ handler/handler_base.cpp
â”‚  â”œâ”€ engine/
â”‚  â”‚  â””â”€ engine.cpp
â”‚  â””â”€ ml/
â”‚     â”œâ”€ registry.cpp
â”‚     â”œâ”€ trainer.cpp
â”‚     â”œâ”€ dataset.cpp
â”‚     â””â”€ models/
â”‚        â””â”€ cnn_mnist/
â”‚           â”œâ”€ model.hpp
â”‚           â””â”€ model.cpp
â”œâ”€ config/
â”‚  â”œâ”€ engine-config.json
â”œâ”€ php/
â”‚  â”œâ”€ index.php
â”‚  â””â”€ .env.php.dist
â””â”€ README.md
```

---

## 4. ë¹Œë“œ & ì‹¤í–‰

### ì˜ì¡´ì„±
- CMake 3.20+
- Clang/GCC (macOS AppleClang OK)
- LibTorch (CPU or CUDA ë¹Œë“œì™€ ì¼ì¹˜)
- (macOS) brew install libomp

### ë¹Œë“œ
```sh
bash ./build.sh
# [100%] Built target ml_engine
```

### ëŸ°íƒ€ì„ í™˜ê²½
```sh
export DYLD_LIBRARY_PATH="$(brew --prefix libomp)/lib:third_party/libtorch/lib:${DYLD_LIBRARY_PATH:-}"
```

### CLI í•™ìŠµ (MNIST)
```sh
build/ml_engine train-cli cnn_mnist
# [epoch 1] loss=1.37270 val_acc=0.7693
# [epoch 2] loss=0.65143 val_acc=0.8713
# [epoch 3] loss=0.44448 val_acc=0.9037
# CLI training finished: cnn_mnist
```

### ì²´í¬í¬ì¸íŠ¸ í™•ì¸
```sh
ls -lh runs/cnn_mnist
# epoch_1.pt  epoch_2.pt  epoch_3.pt  (ê° ~85KB)
```

---

## 5. REST API

### 5.1 ì„œë²„ ê¸°ë™

```bash
# ì„œë²„ ëª¨ë“œ (ì¸ì ì—†ìŒ)
./build/ml_engine

# ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìœ„ì¹˜
# ./config/engine-config.json
#   - port: HTTP í¬íŠ¸ (ê¸°ë³¸: 18080)
#   - threads: ì›Œì»¤ ìŠ¤ë ˆë“œ ìˆ˜
#   - routes: í™œì„±í™”í•  ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡
#   - llm_backend: LLM ì‹¤í–‰ ê²½ë¡œ ë° ì˜µì…˜
```

### ì„œë²„ ê¸°ë™ ì‹œ ì¶œë ¥ ëª¨ìŠµ
```
[INFO] [2025-08-14 17:31:06] - Route: [1] /health
[INFO] [2025-08-14 17:31:06] - Route: [1] /ml/models
[INFO] [2025-08-14 17:31:06] - Route: [3] /ml/train-all
[INFO] [2025-08-14 17:31:06] - Route: [3] /ml/train
[INFO] [2025-08-14 17:31:06] - Route: [3] /llm/generate
Crow API initialized at 0.0.0.0:18080
Crow/1.2.1 server is running ... using 8 threads
```

---

### 5.2 ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡

| ì—”ë“œí¬ì¸íŠ¸         | Method | ì„¤ëª… |
|--------------------|--------|------|
| **`/health`**      | GET    | ì„œë²„ ìƒíƒœ í™•ì¸ (`200 OK` ì‹œ ì •ìƒ) |
| **`/ml/models`**   | GET    | í˜„ì¬ ë“±ë¡ëœ í•™ìŠµ ê°€ëŠ¥í•œ ML ëª¨ë¸ ëª©ë¡ ë°˜í™˜ |
| **`/ml/train`**    | POST   | ì§€ì • ëª¨ë¸ 1ê°œ í•™ìŠµ ì‹œì‘ (JSON ìš”ì²­ ë°”ë”” í•„ìš”) |
| **`/ml/train-all`**| POST   | ë“±ë¡ëœ ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì‹œì‘ |
| **`/llm/generate`**| POST   | LLM(ì˜ˆ: llama.cpp) í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­ |

---

### 5.3 ìš”ì²­/ì‘ë‹µ ì˜ˆì‹œ

#### 1) ì²´í¬
```bash
curl -s http://localhost:18080/health
# ì‘ë‹µ
{"service":"ml-engine","status":"ok"}
```

#### 2) ë“±ë¡ ëª¨ë¸ ì¡°íšŒ
```bash
curl -s http://localhost:18080/ml/models
# ì‘ë‹µ
{"models":["cnn_mnist"]}
```

#### 3) ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ
```bash
curl -s -X POST http://localhost:18080/ml/train \
  -H "Content-Type: application/json" \
  -d '{
        "model": "cnn_mnist",
        "epochs": 1,
        "batch_size": 64,
        "dataset_root": "./data/mnist",
        "ckpt_dir": "./runs/cnn_mnist_from_api"
      }'

# ì‘ë‹µ
{
  "model": "cnn_mnist",
  "status": "ok"
}
```

#### 4) ì „ì²´ ëª¨ë¸ í•™ìŠµ
```bash
curl -s -X POST http://localhost:18080/ml/train-all \
  -H "Content-Type: application/json" \
  -d '{
        "epochs": 1,
        "batch_size": 64,
        "dataset_root": "./data/mnist"
      }'

# ì‘ë‹µ
{
  "results": [
    {
      "model": "cnn_mnist",
      "status": "ok"
    }
  ]
}
```

#### 5) LLM í…ìŠ¤íŠ¸ ìƒì„±
```bash
curl -s -X POST http://localhost:18080/llm/generate \
  -H "Content-Type: application/json" \
  -d '{
        "backend": "llama",
        "prompt": "Hello from ml-engine",
        "extra_args": ["-m", "./models/model.gguf", "-n", "64"]
      }'

# ì‘ë‹µ ì˜ˆì‹œ (LLM ë°±ì—”ë“œ ì„¤ì •ì— ë”°ë¼ ë‹¤ë¦„)
{"status":"ok","output":"Hello from ml-engine..."}
```

---

### 5.4 ì‹¤í–‰ ëª¨ë“œì™€ ìœ íš¨ ì¸ì

| ëª…ë ¹ ì˜ˆì‹œ | ë™ì‘ |
|-----------|------|
| `./ml_engine` | ì„œë²„ ëª¨ë“œ (REST API í™œì„±) |
| `./ml_engine --help=server` | ì„œë²„ ëª¨ë“œ ê°€ì´ë“œ ì¶œë ¥ |
| `./ml_engine train-cli` | ê¸°ë³¸ ëª¨ë¸(`cnn_mnist`) CLI í•™ìŠµ |
| `./ml_engine train-cli cnn_mnist` | ì§€ì • ëª¨ë¸ CLI í•™ìŠµ |
| `./ml_engine f` | ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ ì‹¤í–‰ |
| `./ml_engine tr` | âŒ ì—ëŸ¬: ì˜ëª»ëœ ì¸ì â†’ ì„œë²„ ë¯¸ê¸°ë™ |

---

### 5.5 íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

- **404 ì—ëŸ¬** â†’ í•´ë‹¹ ì—”ë“œí¬ì¸íŠ¸ê°€ ë¹Œë“œì— í¬í•¨ë˜ì§€ ì•Šì•˜ê±°ë‚˜ êµ¬í˜„ë˜ì§€ ì•ŠìŒ  
- **í¬íŠ¸ ì¶©ëŒ** â†’ `config/engine-config.json`ì—ì„œ í¬íŠ¸ ë³€ê²½  
- **LLM ì‘ë‹µì´ 200ì¸ë° ë‚´ìš© ì—†ìŒ** â†’ ë°±ì—”ë“œ ê²½ë¡œì™€ `.gguf` ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸  
- **`train-cli` ì‹¤í–‰ ì‹œ ë°ì´í„°ì…‹ ì˜¤ë¥˜** â†’ `dataset_root` ê²½ë¡œì— MNIST ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸  

  
---

## 6. í•™ìŠµ/ì¶”ë¡  ì˜ˆì‹œ

### CLI í•™ìŠµ
```sh
build/ml_engine train-cli cnn_mnist
```

### llama.cpp ë°”ì´ë„ˆë¦¬ ì§ì ‘ í…ŒìŠ¤íŠ¸
```sh
llama-cli -p "í…ŒìŠ¤íŠ¸\n\n" -t 8 -c 2048 --temp 0.7 --top-k 40 --top-p 0.95 \
  -m deepseek-coder-v2-lite-instruct-q4_k_m.gguf -ngl 0 --simple-io -n 64 -r "User:"
```

### REST ì¶”ë¡ 
```sh
curl -sS -X POST http://localhost:18080/llm/generate \
  -H "Content-Type: application/json" \
  -d '{ ... }'
```
ì„œë²„ ë¡œê·¸ì—ëŠ” load time / prompt eval time / eval time / TPS ë“± ì„±ëŠ¥ ì§€í‘œê°€ ì¶œë ¥ë©ë‹ˆë‹¤.

---

## 7. ëª¨ë¸ ì¶”ì²œ & ì–‘ìí™” ê°€ì´ë“œ

### ìš©ë„ë³„ ì¶”ì²œ (Apple Silicon, ë¡œì»¬ ì¶”ë¡  ìœ„ì£¼)

#### ë²”ìš© ë¹„ì„œ + ê¸°ë³¸ ì½”ë“œ ë³´ì¡°
- Llama 3.1 Instruct 8B: Q4_K_M(ê¸°ë³¸), Q5_K_M(ì—¬ìœ ) ~4.5GB
- Mistral Instruct 7B: Q4_K_M ~4.1GB
- Phi-3.5-mini Instruct 3.8B: Q4_K_M ~2.2GB

#### ì½”ë“œ ìƒì„± ì¤‘ì‹¬
- Qwen2.5-Coder Instruct 7B: Q4_K_M(ê¸°ë³¸), Q5_K_M ~4.6GB
- CodeLlama Instruct 7B: Q4_K_M ~4.3GB
- DeepSeek-Coder-V2-Lite Instruct 16B: Q4_K_M ~8â€“9GB (16GB RAMâ†‘ ê¶Œì¥)

#### ìš”ì•½
- RAM 16GB: Qwen2.5-Coder-7B-Instruct Q4_K_M
- RAM 32GBâ†‘: Llama 3.1-8B-Instruct Q5_K_M ë˜ëŠ” DeepSeek-Coder-V2-Lite Q4_K_M
- ë§¤ìš° ê°€ë³ê²Œ: Mistral-7B-Instruct Q4_K_M

### ì–‘ìí™” ê°€ì´ë“œ
- Q4_K_M: ê¸°ë³¸ ì¶”ì²œ (ë©”ëª¨ë¦¬â†“, í’ˆì§ˆ ì†ì‹¤ ì ìŒ)
- Q5_K_M: ë©”ëª¨ë¦¬ ì—¬ìœ  ì‹œ í’ˆì§ˆâ†‘
- Q8_0: FP16 ê·¼ì ‘, ë©”ëª¨ë¦¬/ì†ë„ ë¹„ìš© í¼
- ëŸ°íƒ€ì„ ë©”ëª¨ë¦¬: GGUF íŒŒì¼ í¬ê¸° Ã— 1.2~1.4

### íŒŒì¼ ë°°ì¹˜ & í˜¸ì¶œ ì˜ˆì‹œ(JSON í˜ì´ë¡œë“œ)
#### Request
```json
curl -sS -X POST http://localhost:18080/llm/generate \
  -H "Content-Type: application/json" \
  -d '{
    "backend": "llama",
    "prompt": "C++ë¡œ ë©€í‹°ìŠ¤ë ˆë“œ ì˜ˆì œ ì‘ì„±í•´ì¤˜. ì½”ë“œ ë¸”ë¡ìœ¼ë¡œë§Œ ë‹µí•´ì¤˜.",
    "llama_exec_path": "/Users/mac/Desktop/workspace/miniGPT/ml-engine/third_party/llama.cpp/build/bin/llama-cli",
    "n_threads": 8,
    "n_ctx": 1024,
    "temperature": 0.7,
    "top_k": 40,
    "top_p": 0.95,
    "extra_args": [
      "-m","/Users/mac/Desktop/workspace/miniGPT/ml-engine/models/deepseek-coder-v2-lite-instruct-q4_k_m.gguf",
      "-ngl","24",
      "-c","1024",
      "-b","1024",
      "--simple-io",
      "-no-cnv",
      "-n","128"
    ]
  }' | jq .
```

#### Response

```json
{
  "engine": "llama",
  "output": "C++ë¡œ ë©€í‹°ìŠ¤ë ˆë“œ ì˜ˆì œ ì‘ì„±í•´ì¤˜. ì½”ë“œ ë¸”ë¡ìœ¼ë¡œë§Œ ë‹µí•´ì¤˜.\n\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n\nstd::mutex mtx;\n\nvoid print_thread_id(int id) {\n    mtx.lock();\n    std::cout << \"Thread \" << id << \" is running\\n\";\n    mtx.unlock();\n}\n\nint main() {\n    std::thread threads[10];\n    for (int i = 0; i < 10; ++i) {\n        threads[i] = std::thread(print_thread_\n\n",
  "params": {
    "extra_args": [
      "-m",
      "/Users/mac/Desktop/workspace/miniGPT/ml-engine/models/deepseek-coder-v2-lite-instruct-q4_k_m.gguf",
      "-ngl",
      "24",
      "-c",
      "1024",
      "-b",
      "1024",
      "--simple-io",
      "-no-cnv",
      "-n",
      "128"
    ],
    "n_ctx": 1024,
    "n_threads": 8,
    "temperature": 0.699999988079071,
    "top_k": 40,
    "top_p": 0.949999988079071
  },
  "prompt": "C++ë¡œ ë©€í‹°ìŠ¤ë ˆë“œ ì˜ˆì œ ì‘ì„±í•´ì¤˜. ì½”ë“œ ë¸”ë¡ìœ¼ë¡œë§Œ ë‹µí•´ì¤˜."
}
```

---

## 8. ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- ì‹¤í–‰ ê¶Œí•œ: llama_exec_path â†’ chmod +x
- DYLD_LIBRARY_PATH: libomp, third_party/libtorch/lib ì¶”ê°€
- ê¸¸ì´ ì œì–´: n_ctx(ì»¨í…ìŠ¤íŠ¸), -n(ìƒì„± ê¸¸ì´)
- ë¼ì´ì„ ìŠ¤ ì¤€ìˆ˜: ëª¨ë¸/ë°ì´í„°/ì½”ë“œ ê°ê° í™•ì¸
- í…ì„œ ì°¨ì› ì•ˆì „ë§: {N,28,28} â†’ {N,1,28,28} unsqueeze (MNIST 1ì±„ë„ ì „ì œ ì‹œ)
- macOS DataLoader: num_workers>0 ì´ìŠˆ ì‹œ 0ìœ¼ë¡œ

---

## 9. ë¡œë“œë§µ

| ë‹¨ê³„ | ëª©í‘œ | ì™œ/ë¬´ì—‡ |
|------|------|---------|
| 1 | ì•„í‹°íŒ©íŠ¸ í™•ì¸ | runs/cnn_mnist/epoch_*.pt ìƒì„± í™•ì¸ |
| 2 | ì¶”ë¡  ë£¨í‹´ ì¶”ê°€ | ì²´í¬í¬ì¸íŠ¸ ë¡œë”© â†’ ë‹¨ì¼/ë°°ì¹˜ ì˜ˆì¸¡ |
| 3 | REST ì˜ˆì¸¡ API | POST /ml/predict (Crow) |
| 4 | ë² ìŠ¤íŠ¸ë§Œ ì €ì¥ | ìµœê³  ê²€ì¦ì ë§Œ ì €ì¥(early-stop/ìµœê³ ì  ê´€ë¦¬) |
| 5 | í•˜ì´í¼íŒŒë¼ë¯¸í„° ì œì–´ | CLI/RESTë¡œ epochs/batch/lr/workers ë…¸ì¶œ |
| 6 | ì˜êµ¬ ëŸ¬ntime ê²½ë¡œ | rpath ë˜ëŠ” ì‰˜ ì´ˆê¸°í™”ë¡œ DYLD ì˜êµ¬í™” |
| 7 | PHP UI ì—°ë™ | Train/Predict ë²„íŠ¼(ê³µìœ í˜¸ìŠ¤íŒ…) |

---

## 10. ìì£¼ ë°œìƒí•˜ëŠ” ì´ìŠˆ

- CUDA/cuDNN/LibTorch ë¶ˆì¼ì¹˜ â†’ ë¡œë”©/ë§í‚¹ ì˜¤ë¥˜. ë²„ì „ ì •í•©ì„± í•„ìˆ˜
- macOS í¬í¬ ì œì•½ â†’ DataLoader(num_workers>0) ë¬¸ì œ ì‹œ 0ìœ¼ë¡œ
- llama.cpp Makefile ê²½ê³  â†’ CMake ë¹Œë“œ ì‚¬ìš©
- ì¶œë ¥ì´ ì¤‘ê°„ì— ëŠê¹€ â†’ -n(ìƒì„± ê¸¸ì´) ë° n_ctx(ì»¨í…ìŠ¤íŠ¸) í™•ëŒ€
- CPUë§Œ ëŠë¦¼ â†’ llama.cpp Metal ê°€ì† (-DGGML_METAL=ON, ì‹¤í–‰ -ngl 99)

---

## 11. ìš©ì–´ ì‚¬ì „

- n_ctx: ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´(í† í°)
- -n / n_predict: ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
- n_threads: CPU ìŠ¤ë ˆë“œ ìˆ˜
- -ngl: GPU(Metal) ì˜¤í”„ë¡œë”© ë ˆì´ì–´ ìˆ˜ (0=CPU, 99=ìµœëŒ€)
- -c/-b: ì»¨í…ìŠ¤íŠ¸/ë°°ì¹˜ í¬ê¸°
- --simple-io: ë‹¨ìˆœ STDIO I/O
- -no-cnv: chat template ë¹„í™œì„±í™”
- temperature/top_k/top_p: ìƒ˜í”Œë§ ì œì–´
- repeat_penalty: ë°˜ë³µ ì–µì œ
- BOS/EOS/EOG/PAD: ì‹œì‘/ë/ìƒì„±ì¢…ë£Œ/íŒ¨ë”© í† í°
- FIM: Fill-In-the-Middle í† í° (PRE/SUF/MID)
- rope(yarn): RoPE ìœ„ì¹˜ ì¸ì½”ë”©(+ê¸´ ì»¨í…ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ë§)
- kv cache: K/V ìºì‹œ(ë©”ëª¨ë¦¬â†”ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„)
- prompt eval / eval time: í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬/ìƒì„± í† í°ë‹¹ ì†Œìš”
- TPS: ì´ˆë‹¹ ìƒì„± í† í° ìˆ˜

---


## 12. ë¼ì´ì„ ìŠ¤

<div align="left">
<details open>
<summary><strong>MIT License ì „ë¬¸</strong></summary>

<blockquote style="background:#f5f5f5;border-radius:12px;padding:16px 24px;box-shadow:0 2px 8px #eee;">

MIT License<br>
Copyright (c) 2025 â€¦<br><br>
Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the â€œSoftwareâ€), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:<br><br>
The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.<br><br>
THE SOFTWARE IS PROVIDED â€œAS ISâ€, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.<br><br>

</blockquote>
</details>
</div>

---

## 13. ë¶€ë¡: ë¹ ë¥¸ ì‹œì‘

```sh
# 1) ë¹Œë“œ
bash ./build.sh

# 2) ëŸ°íƒ€ì„ ê²½ë¡œ
export DYLD_LIBRARY_PATH="$(brew --prefix libomp)/lib:third_party/libtorch/lib:${DYLD_LIBRARY_PATH:-}"

# 3) í•™ìŠµ (MNIST)
build/ml_engine train-cli cnn_mnist
ls runs/cnn_mnist   # epoch_*.pt í™•ì¸

# 4) ì„œë²„ ê¸°ë™
build/ml_engine
curl -s http://localhost:18080/health
curl -s http://localhost:18080/ml/models

# 5) LLM ì¶”ë¡  (llama.cpp ì—°ë™)
curl -sS -X POST http://localhost:18080/llm/generate \
  -H "Content-Type: application/json" \
  -d '{ ... }'
```

---

## 14. DeepSeek-Coder-V2-Lite Instruct ì„ íƒ ë° ì‹¤ì „ ë¡œê·¸

<details>
<summary>ì‹¤ì „ ë¡œê·¸ ë° ìƒì„¸ ì„¤ëª… (í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°)</summary>

**DeepSeek-Coder-V2-Lite Instructë¡œ ì„ íƒ**  
https://huggingface.co/models

ë§¨ ì•„ë˜ìª½ `sugatoxay/DeepSeek-Coder-V2-Lite-Instruct-Q4_K_M-GGUF` ë¥¼ ì¶”ì²œí•œ ê±´,
ì§€ê¸ˆ ìƒí™©ì´ â€œìì²´ LLM íŒ¨ë„ì—ì„œ ì¶”ë¡  í…ŒìŠ¤íŠ¸â€ ëª©ì ì´ë¼ì„œ ê°€ì¥ ê°€ë³ê³  ì‹¤í–‰ì´ ë¹ ë¥¸ `GGUF` ë³€í™˜ë³¸ì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

https://huggingface.co/sugatoray/DeepSeek-Coder-V2-Lite-Instruct-Q4_K_M-GGUF/blob/main/deepseek-coder-v2-lite-instruct-q4_k_m.gguf

â€¢ ë°ì´í„° ì°¨ì› ë³´ì •ì€ ëª¨ë¸ êµ¬í˜„(ì˜ˆ: cnn_mnist::Model)ì´ NCHW(1ì±„ë„) ì „ì œë¥¼ ê°€ì§ˆ ë•Œë§Œ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¯¸ MNIST DataSetì´ {N,1,28,28}ë¡œ ë°°ì¹˜í•œë‹¤ë©´ unsqueeze ë¸”ë¡ì€ ê±´ë„ˆë›°ì§€ë§Œ, ìœ„ì²˜ëŸ¼ ì¡°ê±´ë¶€ë¡œ ì•ˆì „ë§ì„ ë‘ë©´ í™˜ê²½ ì°¨ì´(C++ API ë²„ì „/ì»¤ìŠ¤í…€ Dataset)ì—ì„œë„ ì•ˆì „í•©ë‹ˆë‹¤.
â€¢ macOS CPUì—ì„œ num_workers>0ì¼ ë•Œ fork ì œì•½ìœ¼ë¡œ ë“œë¬¼ê²Œ ë¬¸ì œê°€ ìƒê¸°ë©´ cfg.num_workers=0ë¡œ ë‚®ì¶°ë³´ì„¸ìš”.

---

### [build ì™„ë£Œ]
```sh
mac@azabell-mac ml-engine % bash ./build.sh
-- The CXX compiler identification is AppleClang 16.0.0.16000026
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Torch: /Users/mac/Desktop/workspace/miniGPT/ml-engine/third_party/libtorch/lib/libtorch.dylib
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE
-- Configuring done (3.5s)
-- Generating done (0.0s)
-- Build files have been written to: /Users/mac/Desktop/workspace/miniGPT/ml-engine/build
[ 11%] Building CXX object CMakeFiles/ml_engine.dir/src/api/api_server.cpp.o
[ 22%] Building CXX object CMakeFiles/ml_engine.dir/src/ml/registry.cpp.o
[ 33%] Building CXX object CMakeFiles/ml_engine.dir/src/engine/engine.cpp.o
[ 44%] Building CXX object CMakeFiles/ml_engine.dir/src/api/handler/handler_base.cpp.o
[ 55%] Building CXX object CMakeFiles/ml_engine.dir/src/llm/llm_engine.cpp.o
[ 66%] Building CXX object CMakeFiles/ml_engine.dir/src/ml/models/cnn_mnist/model.cpp.o
[ 77%] Building CXX object CMakeFiles/ml_engine.dir/src/main.cpp.o
[ 88%] Building CXX object CMakeFiles/ml_engine.dir/src/ml/dataset.cpp.o
[100%] Linking CXX executable ml_engine
[100%] Built target ml_engine
```

---

```sh
$ export DYLD_LIBRARY_PATH="$(brew --prefix libomp)/lib:../third_party/libtorch/lib:${DYLD_LIBRARY_PATH:-}"
```

---

### [ìµœì¢… í…ŒìŠ¤íŠ¸]
#### Request
```sh
$ mac@azabell-mac ml-engine % curl -s http://localhost:18080/health
curl -s http://localhost:18080/ml/models
curl -s -X POST http://localhost:18080/llm/generate \
  -H "Content-Type: application/json" \
  -d '{"backend":"mock","prompt":"Hello"}'
```

#### Response
```json
{
  "service": "ml-engine",
  "status": "ok"
}
{
  "models": [
    "cnn_mnist"
  ]
}
{
  "engine": "mock",
  "output": "[mock] codegen for: Hello",
  "params": {
    "extra_args": [],
    "n_ctx": 512,
    "n_threads": 4,
    "temperature": 0.800000011920929,
    "top_k": 40,
    "top_p": 0.949999988079071
  },
  "prompt": "Hello"
}
```

---

### [llama.cpp ë¹Œë“œ ë° í…ŒìŠ¤íŠ¸]
```sh
cd /Users/mac/Desktop/workspace/miniGPT/ml-engine/third_party/llama.cpp
git pull
make clean
cmake -B build -DGGML_METAL=ON
cmake --build build -j
```

ë¹Œë“œ ë¡œê·¸ ë° ê²½ê³ , Metal/CPU ë°±ì—”ë“œ ê°ì§€, OpenMP ë¯¸íƒì§€ ê²½ê³  ë“±ì€ ì‹¤ì œ í™˜ê²½ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

### [LLM ë°ëª¨ ì‹¤í–‰ ì˜ˆì‹œ]
```sh
/Users/mac/Desktop/workspace/miniGPT/ml-engine/third_party/llama.cpp/build/bin/llama-cli \
  -p "í…ŒìŠ¤íŠ¸\n\n" \
  -t 8 -c 2048 --temp 0.7 --top-k 40 --top-p 0.95 \
  -m /Users/mac/Desktop/workspace/miniGPT/ml-engine/models/deepseek-coder-v2-lite-instruct-q4_k_m.gguf \
  -ngl 0 --simple-io -n 64 -r "User:"
```

ì‹¤í–‰ ë¡œê·¸, ëª¨ë¸ ë©”íƒ€ë°ì´í„°, í† í° ì •ë³´, Metal/CPU ë©”ëª¨ë¦¬ í• ë‹¹, ì„±ëŠ¥ ì§€í‘œ(TPS, eval time ë“±)ëŠ” ì‹¤ì œ ì¶œë ¥ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

---

### [Crow Server REST API ìš”ì²­/ì‘ë‹µ ì˜ˆì‹œ]
#### Request
```sh
curl -sS -X POST http://localhost:18080/llm/generate \
  -H "Content-Type: application/json" \
  -d '{
    "backend": "llama",
    "prompt": "C++ë¡œ ë©€í‹°ìŠ¤ë ˆë“œ ì˜ˆì œ ì‘ì„±í•´ì¤˜. ì½”ë“œ ë¸”ë¡ìœ¼ë¡œë§Œ ë‹µí•´ì¤˜.",
    "llama_exec_path": "/Users/mac/Desktop/workspace/miniGPT/ml-engine/third_party/llama.cpp/build/bin/llama-cli",
    "n_threads": 8,
    "n_ctx": 1024,
    "temperature": 0.7,
    "top_k": 40,
    "top_p": 0.95,
    "extra_args": [
      "-m","/Users/mac/Desktop/workspace/miniGPT/ml-engine/models/deepseek-coder-v2-lite-instruct-q4_k_m.gguf",
      "-ngl","24",
      "-c","1024",
      "-b","1024",
      "--simple-io",
      "-no-cnv",
      "-n","128"
    ]
  }' | jq .
```

#### Response
```json
{
  "engine": "llama",
  "output": "C++ë¡œ ë©€í‹°ìŠ¤ë ˆë“œ ì˜ˆì œ ì‘ì„±í•´ì¤˜. ì½”ë“œ ë¸”ë¡ìœ¼ë¡œë§Œ ë‹µí•´ì¤˜.\n\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n\nstd::mutex mtx;\n\nvoid print_thread_id(int id) {\n    mtx.lock();\n    std::cout << \"Thread \" << id << \" is running\\n\";\n    mtx.unlock();\n}\n\nint main() {\n    std::thread threads[10];\n    for (int i = 0; i < 10; ++i) {\n        threads[i] = std::thread(print_thread_\n\n",
  "params": {
    "extra_args": [
      "-m",
      "/Users/mac/Desktop/workspace/miniGPT/ml-engine/models/deepseek-coder-v2-lite-instruct-q4_k_m.gguf",
      "-ngl",
      "24",
      "-c",
      "1024",
      "-b",
      "1024",
      "--simple-io",
      "-no-cnv",
      "-n",
      "128"
    ],
    "n_ctx": 1024,
    "n_threads": 8,
    "temperature": 0.699999988079071,
    "top_k": 40,
    "top_p": 0.949999988079071
  },
  "prompt": "C++ë¡œ ë©€í‹°ìŠ¤ë ˆë“œ ì˜ˆì œ ì‘ì„±í•´ì¤˜. ì½”ë“œ ë¸”ë¡ìœ¼ë¡œë§Œ ë‹µí•´ì¤˜."
}
```

ì„œë²„ ì„±ëŠ¥ ë¡œê·¸(TPS, load/prompt/eval time ë“±)ëŠ” ì‹¤ì œ í™˜ê²½ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

### [ì¶”ê°€ íŒ]

- ë°ì´í„° ì°¨ì› ë³´ì •ì€ ëª¨ë¸ êµ¬í˜„(ì˜ˆ: cnn_mnist::Model)ì´ NCHW(1ì±„ë„) ì „ì œë¥¼ ê°€ì§ˆ ë•Œë§Œ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¯¸ MNIST DataSetì´ {N,1,28,28}ë¡œ ë°°ì¹˜í•œë‹¤ë©´ unsqueeze ë¸”ë¡ì€ ê±´ë„ˆë›°ì§€ë§Œ, ìœ„ì²˜ëŸ¼ ì¡°ê±´ë¶€ë¡œ ì•ˆì „ë§ì„ ë‘ë©´ í™˜ê²½ ì°¨ì´(C++ API ë²„ì „/ì»¤ìŠ¤í…€ Dataset)ì—ì„œë„ ì•ˆì „í•©ë‹ˆë‹¤.
- macOS CPUì—ì„œ num_workers>0ì¼ ë•Œ fork ì œì•½ìœ¼ë¡œ ë“œë¬¼ê²Œ ë¬¸ì œê°€ ìƒê¸°ë©´ cfg.num_workers=0ë¡œ ë‚®ì¶°ë³´ì„¸ìš”.

</details>

---

## 15. ë¶€ë¡: DeepSeek-Coder-V2-Lite Instruct GGUF ë©”íƒ€ë°ì´í„° ë° ì‹¤í–‰ ë¡œê·¸ í•´ì„¤

<details>
<summary>ì‹¤í–‰ ë¡œê·¸ ë° ë©”íƒ€ë°ì´í„° ìƒì„¸ í•´ì„¤ (í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°)</summary>

ì•„ë˜ëŠ” llama.cppê°€ DeepSeek-Coder-V2-Lite-Instruct GGUF ëª¨ë¸ì„ ë¡œë“œí•  ë•Œ ì¶œë ¥í•˜ëŠ” ì£¼ìš” ë¡œê·¸ì™€ ê° í•­ëª©ì˜ ì„¤ëª…ì…ë‹ˆë‹¤.

### ëª¨ë¸ ë¡œë”© ë° ë©”íƒ€ë°ì´í„°

- **llama_model_load_from_file_impl: using device Metal (Apple M2) - 10922 MiB free**
  - Metal(Apple GPU)ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ë©°, ì‚¬ìš© ê°€ëŠ¥í•œ VRAM(ë©”ëª¨ë¦¬) ìš©ëŸ‰ì„ í‘œì‹œí•©ë‹ˆë‹¤.

- **llama_model_loader: loaded meta data with 38 key-value pairs and 377 tensors ...**
  - ëª¨ë¸ íŒŒì¼ ë‚´ì— í¬í•¨ëœ ë©”íƒ€ë°ì´í„°(í‚¤-ê°’ ìŒ)ì™€ í…ì„œ(ê°€ì¤‘ì¹˜ ë“±) ê°œìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

#### ì£¼ìš” ë©”íƒ€ë°ì´í„° í•­ëª© ì„¤ëª…

| í‚¤ | ê°’ | ì„¤ëª… |
|----|-----|------|
| general.architecture | deepseek2 | ëª¨ë¸ ì•„í‚¤í…ì²˜ ì´ë¦„ (DeepSeek 2) |
| general.name | DeepSeek-Coder-V2-Lite-Instruct | ëª¨ë¸ ì´ë¦„ |
| deepseek2.block_count | 27 | Transformer ë¸”ë¡(ë ˆì´ì–´) ê°œìˆ˜ |
| deepseek2.context_length | 163840 | ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´(í† í°) |
| deepseek2.embedding_length | 2048 | ì„ë² ë”© ì°¨ì› ìˆ˜ |
| deepseek2.feed_forward_length | 10944 | FFN(Feed Forward Network) ì°¨ì› |
| deepseek2.attention.head_count | 16 | ì–´í…ì…˜ í—¤ë“œ ê°œìˆ˜ |
| deepseek2.attention.head_count_kv | 16 | KV ì–´í…ì…˜ í—¤ë“œ ê°œìˆ˜ |
| deepseek2.rope.freq_base | 10000.0 | RoPE(ìœ„ì¹˜ ì¸ì½”ë”©) ê¸°ë³¸ ì£¼íŒŒìˆ˜ |
| deepseek2.attention.layer_norm_rms_epsilon | 0.000001 | RMSNorm epsilon ê°’ |
| deepseek2.expert_used_count | 6 | ì‚¬ìš©ë˜ëŠ” expert ê°œìˆ˜(MoE êµ¬ì¡°) |
| general.file_type | 15 | íŒŒì¼ íƒ€ì…(ë‚´ë¶€ìš©) |
| deepseek2.leading_dense_block_count | 1 | ì„ í–‰ Dense ë¸”ë¡ ê°œìˆ˜ |
| deepseek2.vocab_size | 102400 | í† í¬ë‚˜ì´ì €ì˜ vocab í¬ê¸° |
| deepseek2.attention.kv_lora_rank | 512 | KV LoRA ë­í¬(íŒŒë¼ë¯¸í„° íš¨ìœ¨í™”) |
| deepseek2.attention.key_length | 192 | ì–´í…ì…˜ key ë²¡í„° ì°¨ì› |
| deepseek2.attention.value_length | 128 | ì–´í…ì…˜ value ë²¡í„° ì°¨ì› |
| deepseek2.expert_feed_forward_length | 1408 | expert FFN ì°¨ì› |
| deepseek2.expert_count | 64 | expert ì „ì²´ ê°œìˆ˜ |
| deepseek2.expert_shared_count | 2 | expert ê³µìœ  ê°œìˆ˜ |
| deepseek2.expert_weights_scale | 1.0 | expert ê°€ì¤‘ì¹˜ ìŠ¤ì¼€ì¼ |
| deepseek2.rope.dimension_count | 64 | RoPE ì°¨ì› ìˆ˜ |
| deepseek2.rope.scaling.type | yarn | RoPE ìŠ¤ì¼€ì¼ë§ ë°©ì‹(yarn: ê¸´ ì»¨í…ìŠ¤íŠ¸ ì§€ì›) |
| deepseek2.rope.scaling.factor | 40.0 | RoPE ìŠ¤ì¼€ì¼ë§ íŒ©í„° |
| deepseek2.rope.scaling.original_context_length | 4096 | ì›ë˜ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ |
| deepseek2.rope.scaling.yarn_log_multiplier | 0.0707 | yarn ìŠ¤ì¼€ì¼ë§ ë¡œê·¸ ë©€í‹°í”Œë¼ì´ì–´ |
| tokenizer.ggml.model | gpt2 | í† í¬ë‚˜ì´ì € ëª¨ë¸(gpt2 ê¸°ë°˜) |
| tokenizer.ggml.pre | deepseek-llm | í† í¬ë‚˜ì´ì € prefix |
| tokenizer.ggml.tokens | arr[str,102400] | í† í° ë¦¬ìŠ¤íŠ¸(102400ê°œ) |
| tokenizer.ggml.token_type | arr[i32,102400] | í† í° íƒ€ì… ë¦¬ìŠ¤íŠ¸ |
| tokenizer.ggml.merges | arr[str,99757] | BPE ë³‘í•© ê·œì¹™ ë¦¬ìŠ¤íŠ¸ |
| tokenizer.ggml.bos_token_id | 100000 | BOS(ë¬¸ì¥ ì‹œì‘) í† í° ID |
| tokenizer.ggml.eos_token_id | 100001 | EOS(ë¬¸ì¥ ë) í† í° ID |
| tokenizer.ggml.padding_token_id | 100001 | PAD(íŒ¨ë”©) í† í° ID |
| tokenizer.ggml.add_bos_token | true | BOS í† í° ìë™ ì¶”ê°€ ì—¬ë¶€ |
| tokenizer.ggml.add_eos_token | false | EOS í† í° ìë™ ì¶”ê°€ ì—¬ë¶€ |
| tokenizer.chat_template | ... | ëŒ€í™” í…œí”Œë¦¿(í”„ë¡¬í”„íŠ¸ í¬ë§·) |
| general.quantization_version | 2 | ì–‘ìí™” ë²„ì „ |

- **type f32/q4_K/q5_0/q8_0/q6_K: ... tensors**
  - ê° ì–‘ìí™” íƒ€ì…ë³„ í…ì„œ ê°œìˆ˜(f32: float, q4_K: 4ë¹„íŠ¸ ì–‘ìí™” ë“±)

- **print_info: file format = GGUF V3 (latest)**
  - GGUF íŒŒì¼ í¬ë§· ë²„ì „(ìµœì‹ )
- **print_info: file type   = Q4_K - Medium**
  - ì–‘ìí™” íƒ€ì…(Q4_K: 4ë¹„íŠ¸, Medium)
- **print_info: file size   = 9.65 GiB (5.28 BPW)**
  - ëª¨ë¸ íŒŒì¼ í¬ê¸° ë° BPW(bits per weight)

### í† í¬ë‚˜ì´ì € ë° íŠ¹ìˆ˜ í† í°

- **BOS token        = 100000 '<ï½œbeginâ–ofâ–sentenceï½œ>'**
- **EOS token        = 100001 '<ï½œendâ–ofâ–sentenceï½œ>'**
- **PAD token        = 100001 '<ï½œendâ–ofâ–sentenceï½œ>'**
- **FIM PRE/SUF/MID token = 100003/100002/100004**
  - FIM(Fill-In-the-Middle) í”„ë¡¬í”„íŠ¸ìš© íŠ¹ìˆ˜ í† í°
- **EOG token        = 100001 '<ï½œendâ–ofâ–sentenceï½œ>'**
- **max token length = 256**
  - í•œ í† í°ì˜ ìµœëŒ€ ê¸¸ì´

### ëª¨ë¸ ë¡œë”© ë° ì‹¤í–‰ í™˜ê²½

- **load_tensors: loading model tensors, this can take a while... (mmap = true)**
  - í…ì„œ(ê°€ì¤‘ì¹˜) ë¡œë”© ì¤‘, mmap(ë©”ëª¨ë¦¬ ë§¤í•‘) ì‚¬ìš©
- **load_tensors: offloading 0 repeating layers to GPU**
  - ë°˜ë³µ ë ˆì´ì–´ë¥¼ GPUë¡œ ì˜¤í”„ë¡œë”©(ì—¬ê¸°ì„  0)
- **CPU_Mapped model buffer size = 9880.47 MiB**
  - CPUì— ë§¤í•‘ëœ ëª¨ë¸ ë²„í¼ í¬ê¸°

### llama_context ë° ì‹¤í–‰ íŒŒë¼ë¯¸í„°

- **llama_context: constructing llama_context**
  - ì¶”ë¡  ì»¨í…ìŠ¤íŠ¸ ìƒì„±
- **n_seq_max     = 1**
  - ìµœëŒ€ ì‹œí€€ìŠ¤ ê°œìˆ˜(ëŒ€í™” ì„¸ì…˜)
- **n_ctx         = 2048**
  - ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´(í† í°)
- **n_batch       = 2048**
  - ë°°ì¹˜ í¬ê¸°
- **causal_attn   = 1**
  - ì¸ê³¼ì  ì–´í…ì…˜ ì‚¬ìš©
- **kv_unified    = false**
  - KV ìºì‹œ í†µí•© ì—¬ë¶€
- **freq_base     = 10000.0**
  - RoPE ì£¼íŒŒìˆ˜
- **n_ctx_per_seq (2048) < n_ctx_train (163840) -- the full capacity of the model will not be utilized**
  - ì‹¤ì œ ì¶”ë¡  ì»¨í…ìŠ¤íŠ¸ê°€ í•™ìŠµ ì‹œ ìµœëŒ€ê°’ë³´ë‹¤ ì‘ì•„ ì „ì²´ ìš©ëŸ‰ì„ ë‹¤ ì“°ì§€ ì•ŠìŒ

### Metal(GPU) í™˜ê²½ ì •ë³´

- **ggml_metal_init: found device: Apple M2**
  - Metal ë°±ì—”ë“œì—ì„œ Apple M2 GPU ê°ì§€
- **ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB**
  - Metalì—ì„œ ì¶”ì²œí•˜ëŠ” ìµœëŒ€ ì›Œí‚¹ì…‹(ë©”ëª¨ë¦¬) í¬ê¸°
- **ggml_metal_init: skipping kernel_xxx (not supported)**
  - ì§€ì›í•˜ì§€ ì•ŠëŠ” ì»¤ë„(ì—°ì‚°)ì€ ìŠ¤í‚µ

### ê¸°íƒ€ ì‹¤í–‰ íŒŒë¼ë¯¸í„° ë° ìƒ˜í”Œë§

- **main: llama threadpool init, n_threads = 8**
  - ì¶”ë¡ ì— ì‚¬ìš©í•  ìŠ¤ë ˆë“œ ìˆ˜
- **main: chat template is available, enabling conversation mode (disable it with -no-cnv)**
  - ëŒ€í™” í…œí”Œë¦¿ í™œì„±í™”(ê¸°ë³¸), -no-cnvë¡œ ë¹„í™œì„±í™” ê°€ëŠ¥
- **sampler params: ...**
  - ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°(ë°˜ë³µ ì–µì œ, top_k, top_p, temperature ë“±)
- **generate: n_ctx = 2048, n_batch = 2048, n_predict = 64, n_keep = 1**
  - ì¶”ë¡  ì‹œ ì»¨í…ìŠ¤íŠ¸, ë°°ì¹˜, ìƒì„± í† í° ìˆ˜, ìœ ì§€ í† í° ìˆ˜

### ëŒ€í™” ì˜ˆì‹œ ë° í”„ë¡¬í”„íŠ¸

- **main: chat template example:**
  - í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ: User/Assistant ì—­í• 

---

ì´ ë¡œê·¸ë“¤ì€ GGUF ëª¨ë¸ì˜ êµ¬ì¡°, í† í¬ë‚˜ì´ì €, ì‹¤í–‰ í™˜ê²½, ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° ë“± LLM ì¶”ë¡ ì˜ ëª¨ë“  í•µì‹¬ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ê° í•­ëª©ì€ ì‹¤ì œ ì¶”ë¡  í’ˆì§ˆ, ì†ë„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ë¯€ë¡œ, í™˜ê²½ì— ë§ê²Œ ì¡°ì •í•˜ë©° í™œìš©í•˜ì„¸ìš”.

</details>

---

## 16 ë¶€ë¡: ì„œë²„ ê¸°ë™ ë° ë¼ì´ì„ ìŠ¤ ì²´í¬ ë™ì‘
<details>
<summary>ë¼ì´ì„ ìŠ¤ ìƒì„¸ ì„¤ëª… (í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°)</summary>

### 1. config/engine-config.json êµ¬ì¡°

```json
{
  "common": {
    "api_port": 18080,
    "license": "./license.json",
    "public_key_path": "./public_key.pem"
  }
}
```
- `license`: ì‹¤ì œ ë¼ì´ì„ ìŠ¤ JSON íŒŒì¼ ê²½ë¡œ
- `public_key_path`: ì„œëª… ê²€ì¦ìš© ê³µê°œí‚¤ ê²½ë¡œ

### 2. config/license.json ìƒ˜í”Œ

```json
{
  "license_id": "trial-2025-08-14",
  "issued_to": "user@example.com",
  "issued_at": "2025-08-14T00:00:00Z",
  "expires_at": "2025-09-14T00:00:00Z",
  "public_key_path": "public_key.pem",
  "signature": "<base64-signature>",
  "features": ["api", "train", "predict"],
  "notes": "Demo license for engine activation."
}
```

### 3. config/public_key.pem ìƒ˜í”Œ

```
-----BEGIN PUBLIC KEY-----
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEArandompublickeydemo
-----END PUBLIC KEY-----
```

### 4. utils::loadEngineConfig (engine-config.json íŒŒì‹±)
- `license`, `public_key_path` í•„ë“œë¥¼ ì½ì–´ ì‹¤ì œ ê²½ë¡œë¡œ ë³€í™˜
- êµ¬ì¡°ì²´ì— ì±„ì›Œë„£ì–´ ì´í›„ ì—”ì§„ ì´ˆê¸°í™”ì— ì‚¬ìš©

### 5. secure::loadLicenseFile (license.json ë¡œë”©)
- ë¼ì´ì„ ìŠ¤ íŒŒì¼ì„ í†µì§¸ë¡œ ì½ì–´ ë¬¸ìì—´ë¡œ ë°˜í™˜
- ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì•”í˜¸í™”/ì„œëª… ê²€ì¦ í•„ìš”

### 6. engine.cppì˜ ë¼ì´ì„ ìŠ¤ ì—°ë™ íë¦„

- configì—ì„œ license/public_key_path ê²½ë¡œë¥¼ ì½ì–´ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³´ì •
- ë¼ì´ì„ ìŠ¤ íŒŒì¼ì„ ì½ì–´ JSON íŒŒì‹±
- ë¼ì´ì„ ìŠ¤ ë‚´ public_key_pathê°€ ìˆìœ¼ë©´ ìš°ì„  ì ìš©
- secure::AntiPiracy, SignatureVerifier ë“±ìœ¼ë¡œ ë¬´ê²°ì„±/ì„œëª… ê²€ì¦
- features, expires_at ë“± ë¼ì´ì„ ìŠ¤ í•„ë“œ í™œìš© ê°€ëŠ¥

#### ì£¼ìš” ì½”ë“œ íë¦„
```cpp
// 1) ê²½ë¡œ ë³´ì • ë° ë¡œê·¸
std::string license_json_path = m_config.common.license;
std::string public_key_path = m_config.common.public_key_path;
// ìƒëŒ€ê²½ë¡œ â†’ ì ˆëŒ€ê²½ë¡œ ë³´ì •
std::filesystem::path config_dir = std::filesystem::path(m_config_filepath).parent_path();
std::filesystem::path abs_public_key_path = config_dir / public_key_path;
public_key_path = abs_public_key_path.string();

// 2) ë¼ì´ì„ ìŠ¤ íŒŒì¼ ë¡œë”©
std::string license_json;
secure::loadLicenseFile(license_json_path, license_json);

// 3) ë¼ì´ì„ ìŠ¤ JSON íŒŒì‹± ë° public_key_path ìš°ì„  ì ìš©
auto root = nlohmann::json::parse(license_json);
if (root.contains("public_key_path")) {
    std::filesystem::path license_dir = std::filesystem::path(license_json_path).parent_path();
    std::filesystem::path abs_license_public_key_path = license_dir / root["public_key_path"].get<std::string>();
    public_key_path = abs_license_public_key_path.string();
}

// 4) ë¬´ê²°ì„±/ì„œëª… ê²€ì¦
secure::AntiPiracy::verifyProgramIntegrity();
secure::AntiPiracy::activateOnlineFromJson(license_json);
secure::SignatureVerifier::verifySignatureFromJson(license_json, license_json_path);
```

### 7. ì‹¤ì œ í™œìš© ì˜ˆì‹œ
- ë¼ì´ì„ ìŠ¤ ë§Œë£Œ, feature ì œí•œ, ì„œëª… ê²€ì¦ ë“± ì—”ì§„ ë™ì‘ ì œì–´ ê°€ëŠ¥
- ì˜ˆ: `features`ì— "train"ì´ ì—†ìœ¼ë©´ í•™ìŠµ API ë¹„í™œì„±í™” ë“±
</details>

---

## 17. ì•„í‚¤í…ì²˜ ê³ ë„í™” ë° êµ¬í˜„ ê³„íš(ìì²´ LLM v1 ë¡œë“œë§µ)

ìì²´ LLM v1 íŒŒì´í”„ë¼ì¸ê³¼ ì„œë¹™ ì•„í‚¤í…ì²˜ëŠ” ìœ„ì˜ ë‹¨ê³„ë³„ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë”°ë¼ ì ì§„ì ìœ¼ë¡œ í™•ì¥ë©ë‹ˆë‹¤.  
ê° ë‹¨ê³„(P0~P2)ë³„ë¡œ ê¸°ëŠ¥ êµ¬í˜„, í’ˆì§ˆ í‰ê°€, ìš´ì˜/ë³´ì•ˆ ê°•í™”ê°€ ë³‘í–‰ë˜ë©°,  
ìµœì¢…ì ìœ¼ë¡œëŠ” GGUF ê¸°ë°˜ì˜ ê²½ëŸ‰ LLMì„ ì•ˆì •ì ìœ¼ë¡œ ì„œë¹™/í•™ìŠµ/ë°°í¬í•  ìˆ˜ ìˆëŠ” C++ ì—”ì§„ìœ¼ë¡œ ì™„ì„±ë©ë‹ˆë‹¤.

> ëª©ì : `ml-engine`ì„ **ì•ˆì •ì ì¸ LLM ì„œë¹™ ê²Œì´íŠ¸ì›¨ì´ + C++/LibTorch í•™ìŠµ ì—”ì§„**ìœ¼ë¡œ ì™„ì„±í•˜ê³ ,  
> **ìì²´ LLM v1**(ì†Œí˜• â†’ ì§€ì‹œíŠœë‹ â†’ ì •ë ¬)ì„ ë°°í¬ ê°€ëŠ¥í•œ í˜•íƒœ(GGUF)ë¡œ ì„ ìˆœí™˜ êµ¬ì¶•

### 17.1 ì „ì²´ êµ¬ì¡°(ê°œìš”)

```mermaid
flowchart LR
  subgraph Client
    U[CLI / Web / PHP UI]
  end

  subgraph Serving[Crow C++ Serving Layer]
    A[REST API / SSE]
    B[Orchestrator\n(preset, routing, auth/rate-limit)]
    C[Metrics/Logs\n(TPS, latencies, errors)]
  end

  subgraph Pool[LLM Runtime Pool]
    P1[llama-server #1]
    P2[llama-server #2]
    Pn[llama-server #N]
  end

  subgraph Registry[Model Registry]
    R1[GGUF(v0/v0.5/v1.0)]
    R2[Tokenizer.json]
    R3[Presets.json]
  end

  subgraph Training[Training Pipeline]
    T1[Data Ingest/ì •ì œ\n(dedup, PII, ìƒ˜í”Œë§)]
    T2[Tokenizer í•™ìŠµ(BPE/32k)]
    T3[Pretraining(â‰¤300M)]
    T4[SFT/QLoRA]
    T5[DPO/ORPO]
    T6[í‰ê°€(LM Eval/HumanEval)]
    T7[ë³€í™˜: safetensorsâ†’GGUF]
  end

  U --> A --> B -->|prompt/preset| Pool
  Pool -->|stream tokens| A
  B --> C
  Registry --> Pool
  Training -->|v1.0.gguf| Registry
  B -->|model select| Registry

  classDef box fill:#f8f9fa,stroke:#aaa,rx:6,ry:6;
  class U,A,B,C,P1,P2,Pn,R1,R2,R3,T1,T2,T3,T4,T5,T6,T7 box;
```
---

### ì•„í‚¤í…ì²˜ êµ¬ì„± ë° ë°ì´í„° íë¦„ ì„¤ëª…

#### 1. ì‚¬ìš©ìê°€ ì ‘ì†í•˜ëŠ” ë¶€ë¶„ (Client)
- **CLI / Web UI**  
  ì‚¬ìš©ìëŠ” í„°ë¯¸ë„ ëª…ë ¹ì–´, ì›¹í˜ì´ì§€ ê¸°ë°˜ UIì—ì„œ AIì—ê²Œ ì§ˆë¬¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.

---

#### 2. AI ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ì„œë²„ (Serving Layer)
- **REST API / SSE**  
  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì„œë²„ê°€ HTTP API ë˜ëŠ” ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°(SSE) ë°©ì‹ìœ¼ë¡œ ë°›ì•„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- **Orchestrator**  
  ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í• ì§€ ê²°ì •í•˜ê³ , ìš”ì²­ ì²˜ë¦¬, ì†ë„ ì œí•œ, ì¸ì¦(ë¡œê·¸ì¸) ë“±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
- **Metrics/Logs**  
  ì„œë²„ì˜ ì²˜ë¦¬ ì‹œê°„, ì—ëŸ¬ ë°œìƒ ì—¬ë¶€ ë“± ìƒíƒœë¥¼ ê¸°ë¡Â·ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.

---

#### 3. ì‹¤ì œ ëª¨ë¸ì´ ëŒì•„ê°€ëŠ” ê³µê°„ (LLM Runtime Pool)
- **llama-server #1, #2, ...**  
  ë™ì¼í•œ AI ëª¨ë¸ í”„ë¡œê·¸ë¨ì„ ì—¬ëŸ¬ ê°œ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ì—¬, ë™ì‹œì— ë§ì€ ìš”ì²­ì„ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

---

#### 4. ëª¨ë¸ ì €ì¥ì†Œ (Model Registry)
- **GGUF**  
  AIê°€ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ í›ˆë ¨ëœ ìµœì¢… ëª¨ë¸ íŒŒì¼.
- **Tokenizer.json**  
  ë¬¸ì¥ì„ AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í† í°(ë‹¨ì–´ ì¡°ê°)ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì‚¬ì „.
- **Presets.json**  
  ë¯¸ë¦¬ ì €ì¥ëœ ëŒ€í™” ìŠ¤íƒ€ì¼ì´ë‚˜ ì„¤ì • ê°’.

---

#### 5. ëª¨ë¸ì„ ë§Œë“œëŠ” ê³¼ì • (Training Pipeline)
1. **ë°ì´í„° ìˆ˜ì§‘Â·ì •ì œ**  
   ì¤‘ë³µ ì œê±°, ê°œì¸ì •ë³´ ì‚­ì œ, ìƒ˜í”Œë§ ë“± ë°ì´í„° ì •ì œ.
2. **Tokenizer í•™ìŠµ**  
   ë¬¸ì¥ì„ í† í°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ë°©ë²•ì„ í›ˆë ¨.
3. **Pretraining**  
   ê¸°ë³¸ ì–¸ì–´ ì´í•´ë ¥ í•™ìŠµ(ì˜ˆ: 3ì–µ íŒŒë¼ë¯¸í„° ì´í•˜).
4. **SFT/QLoRA**  
   íŠ¹ì • ì‘ì—…ì— ë§ì¶˜ ì¶”ê°€ í›ˆë ¨(ì˜ˆ: ê³ ê°ì„¼í„° ë‹µë³€ ìŠ¤íƒ€ì¼).
5. **DPO/ORPO**  
   ë” ì‚¬ëŒë‹¤ìš´ ë‹µë³€ ì„ íƒì„ ìœ„í•œ ì •ë ¬ í›ˆë ¨.
6. **í‰ê°€**  
   ìë™ í‰ê°€(LM Eval) ë° ì§ì ‘ í…ŒìŠ¤íŠ¸(HumanEval).
7. **ë³€í™˜**  
   ëª¨ë¸ íŒŒì¼ì„ GGUF í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¹ ë¥´ê²Œ ì‚¬ìš©.

---

#### ë°ì´í„° íë¦„ ìš”ì•½

1. ì‚¬ìš©ìê°€ ì§ˆë¬¸ ì…ë ¥ (Client)
2. ì„œë²„(Serving Layer)ê°€ ìš”ì²­ì„ ë°›ì•„ ì¡°ìœ¨(Orchestrator)
3. ì‚¬ìš©í•  ëª¨ë¸ì„ Model Registryì—ì„œ í™•ì¸ í›„ LLM Runtime Poolì— ì „ë‹¬
4. ëª¨ë¸ì´ í† í° ë‹¨ìœ„ë¡œ ë‹µë³€ ìƒì„± â†’ ì‚¬ìš©ìì—ê²Œ ìŠ¤íŠ¸ë¦¬ë°
5. ì„œë²„ëŠ” ëª¨ë“  ìš”ì²­ê³¼ ì‘ë‹µì„ ê¸°ë¡(Metrics/Logs)
6. ìƒˆë¡œìš´ ëª¨ë¸ì´ í•™ìŠµë˜ë©´(Training Pipeline) Model Registryì— ë“±ë¡ â†’ ì„œë¹„ìŠ¤ì— ì¦‰ì‹œ ë°˜ì˜

---

> ğŸ’¡ **í•œ ì¤„ ìš”ì•½**  
> ì‚¬ìš©ìê°€ ì§ˆë¬¸í•˜ë©´, ì„œë²„ê°€ ì–´ë–¤ AI ëª¨ë¸ì„ ì“¸ì§€ ì •í•´ì„œ, ì—¬ëŸ¬ ê°œ ì¼œì ¸ ìˆëŠ” ëª¨ë¸ ì¤‘ í•˜ë‚˜ì— ë§¡ê¸°ê³ , ëª¨ë¸ì€ í† í° ë‹¨ìœ„ë¡œ ë‹µì„ ë§Œë“¤ì–´ ë³´ë‚´ì¤€ë‹¤. ëª¨ë¸ì€ ë¯¸ë¦¬ ë°ì´í„° ì •ì œÂ·í›ˆë ¨ ê³¼ì •ì„ ê±°ì³ ì¤€ë¹„ë˜ì–´ ìˆìœ¼ë©°, í•„ìš”í•˜ë©´ ìƒˆ ëª¨ë¸ë¡œ êµì²´í•  ìˆ˜ ìˆë‹¤.

â¸»

## 17.2 Serving/Orchestration ê³ ë„í™”
	â€¢	í”„ë¡œì„¸ìŠ¤ ìŠ¤í° ì œê±°: llama-cli ë§¤ìš”ì²­ ì‹¤í–‰ â†’ llama-server ìƒì£¼ë¡œ ì „í™˜
	â€¢	í’€ë§: llama-server Nê°œ ë¼ìš´ë“œë¡œë¹ˆ + í—¬ìŠ¤ì²´í¬/ë°±í”„ë ˆì…”(ëŒ€ê¸°ì—´ ì œí•œ)
	â€¢	ìŠ¤íŠ¸ë¦¬ë°: /llm/generate/stream (SSE)ë¡œ í† í° ë‹¨ìœ„ ì „ì†¡
	â€¢	ì˜ˆì‹œ:

```json
curl -N -sS -X POST http://localhost:18080/llm/generate/stream \
  -H "Content-Type: application/json" \
  -d '{"prompt":"Hello","preset":"code-lite"}'
```
  

	â€¢	í”„ë¦¬ì…‹ ê´€ë¦¬: presets/*.json (ìƒ˜í”ŒëŸ¬/ì»¨í…ìŠ¤íŠ¸/ì•ˆì „ì˜µì…˜)

```json
{
  "name": "code-lite",
  "n_threads": 8,
  "n_ctx": 2048,
  "temperature": 0.7,
  "top_k": 40,
  "top_p": 0.95,
  "repeat_penalty": 1.1
}
```

	â€¢	í”„ë¡¬í”„íŠ¸ ìºì‹±/KV ì¬ì‚¬ìš©: ë™ì¼ prefix ì¬ì‚¬ìš©(ì‘ë‹µì²´ê° ì§€ì—°â†“)
	â€¢	ê´€ì¸¡ì„±: per-request íì‰/í”„ë¡¬í”„íŠ¸í‰ê°€/ìƒì„±í‰ê°€ ì§€ì—°, TPS, ì—ëŸ¬ì½”ë“œ í‘œì¤€í™”

### ìƒˆ ì—”ë“œí¬ì¸íŠ¸
| ë©”ì„œë“œ | ê²½ë¡œ                  | ì„¤ëª…                                      |
|--------|-----------------------|-------------------------------------------|
| GET    | `/llm/models`         | ë“±ë¡ëœ GGUF ëª¨ë¸/í”„ë¦¬ì…‹ ëª©ë¡               |
| POST   | `/llm/generate/stream`| SSE ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ                          |
| POST   | `/ml/predict`         | LibTorch ëª¨ë¸ ë°°ì¹˜ ì˜ˆì¸¡(í•™ìŠµ ëª¨ë¸)         |
| GET    | `/metrics`            | Prometheus í…ìŠ¤íŠ¸/JSON(ì„ íƒ)               |

â¸»

## 17.3 ì„¤ì • ìŠ¤í‚¤ë§ˆ í™•ì¥ (config/engine-config.json)
```json
{
  "common": { "api_port": 18080, "license": "./license.json", "public_key_path": "./public_key.pem" },
  "serving": {
    "presets_dir": "./presets",
    "default_preset": "code-lite",
    "streaming": { "enabled": true, "keep_alive_ms": 15000 }
  },
  "llm_backend": {
    "type": "llama_server",
    "endpoints": [
      { "url": "http://127.0.0.1:8081", "model": "./models/deepseek-coder-v2-lite-instruct-q4_k_m.gguf" },
      { "url": "http://127.0.0.1:8082", "model": "./models/deepseek-coder-v2-lite-instruct-q4_k_m.gguf" }
    ],
    "timeout_ms": 60000,
    "max_queue": 32
  },
  "security": {
    "api_keys": ["dev-xxx", "ops-yyy"],
    "rate_limit": { "rpm": 120, "burst": 30 }
  }
}
```

â¸»
### 17.4 ìì²´ LLM v1ì„ í–¥í•œ í•™ìŠµ íŒŒì´í”„ë¼ì¸

- **ë°ì´í„°**
  - ì½”ë“œ(60%) / ì¼ë°˜(40%) + í•œê¸€ í¬í•¨
  - ì¤‘ë³µ ì œê±°(dedup), PII í•„í„°ë§, ê¸¸ì´ ê¸°ë°˜ ìƒ˜í”Œë§

- **í† í¬ë‚˜ì´ì €**
  - BPE 32k (tokenizers/SentencePiece)
  - íŠ¹ìˆ˜ í† í°: BOS/EOS/EOG/PAD/FIM

- **ì‚¬ì „í•™ìŠµ(â‰¤300M)**
  - Pre-LN + RoPE êµ¬ì¡°
  - bf16/mixed precision
  - cosine learning rate + warmup
  - gradient clipping
  - ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸ ì €ì¥

- **ì§€ì‹œíŠœë‹(SFT/QLoRA)**
  - ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸/ëŒ€í™” í…œí”Œë¦¿ ì ìš©
  - ë¹„ìš© ìµœì†Œí™” ì „ëµ

- **ì •ë ¬(DPO/ORPO)**
  - ì„ í˜¸ìŒ ìˆ˜ì§‘(ì½”ë”©/ëŒ€í™”)
  - ì•ˆì „ ê±°ë¶€ í…œí”Œë¦¿ ì ìš©

- **í‰ê°€**
  - LM Eval Harness
  - HumanEval/MBPP (pass@1/10 ê¸°ì¤€)

- **ë³€í™˜/ê²€ì¦**
  - PyTorch â†’ safetensors â†’ GGUF ë³€í™˜
  - llama.cppë¡œ ë¡œë”©/ì†ë„/ë©”ëª¨ë¦¬ ì‹¤ì¸¡

- **ë ˆì§€ìŠ¤íŠ¸ë¦¬**
  - models/(gguf), tokenizer/, presets/ ë²„ì „ ê´€ë¦¬ ë° ë¡¤ë°±

â¸»
## 17.5 ë³´ì•ˆ / ë¼ì´ì„ ìŠ¤ / ìš´ì˜

- **Auth / Rate-limit**  
  API í‚¤ ê¸°ë°˜ ì¸ì¦, ë¼ìš°íŠ¸ë³„ RPM(ë¶„ë‹¹ ìš”ì²­)/Burst ì œì–´

- **ë¼ì´ì„ ìŠ¤ ë¯¸ë“¤ì›¨ì–´**  
  feature í”Œë˜ê·¸(train/predict/api)ë¡œ ê¸°ëŠ¥ ì œí•œ, ë§Œë£Œ ì‹œ 403 ë°˜í™˜

- **ì˜¤ë¥˜ í‘œì¤€í™”**  
  íŒŒì¼ ì—†ìŒ, íƒ€ì„ì•„ì›ƒ, OOM ë“± â†’ 4xx/5xx ì½”ë“œ ë° ê¸°ê³„íŒë… ì‚¬ìœ  ì œê³µ

- **ë©”íŠ¸ë¦­**  
  `/metrics` ì—”ë“œí¬ì¸íŠ¸ì—ì„œ TPS, P95/P99 ì§€ì—°, í ê¸¸ì´, ì—ëŸ¬ ë¹„ìœ¨ ë…¸ì¶œ

- **ë°°í¬ ì „ëµ**  
  í”„ë¦¬ì…‹/ëª¨ë¸ ì¹´ë‚˜ë¦¬(ì¼ë¶€ íŠ¸ë˜í”½ ë¶„ì‚°), í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ ì‹œ ìë™ ì œì™¸

---

## 17.6 êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

**P0**  
- llama-server ìƒì£¼ í’€ êµ¬ì„±  
- ë¼ìš´ë“œë¡œë¹ˆ/í—¬ìŠ¤ì²´í¬/ë°±í”„ë ˆì…” êµ¬í˜„  
- SSE(`/llm/generate/stream`) ë° í”„ë¦¬ì…‹ ë¡œë”(presets/*.json)  
- `/llm/models` ëª©ë¡ API  
- ê¸°ë³¸ metrics ë¡œê·¸(TPS/latency)  
- engine-config.json ìŠ¤í‚¤ë§ˆ ë°˜ì˜ ë° ìœ íš¨ì„± ê²€ì‚¬

**P1**  
- í”„ë¡¬í”„íŠ¸ ìºì‹±, KV ì¬ì‚¬ìš©  
- ë¦¬íŠ¸ë¼ì´/íƒ€ì„ì•„ì›ƒ ì •ì±…  
- Tokenizer 32k BPE í•™ìŠµ  
- v0(â‰¤300M) ì‚¬ì „í•™ìŠµ 1~3epoch  
- PyTorchâ†’GGUF ë³€í™˜ íŒŒì´í”„ë¼ì¸  
- llama.cpp ì‹¤ì¸¡ ë¬¸ì„œí™”  
- LM Eval ìµœì†Œì…‹ ìë™í™”(PPL + ê°„ë‹¨ QA)  
- ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ

**P2**  
- SFT/QLoRA + DPO/ORPO ì •ë ¬ â†’ v1.0.gguf ì‚°ì¶œ  
- ì•ˆì „ í•„í„°/ê±°ë¶€ í…œí”Œë¦¿  
- ì¥ê¸° ì»¨í…ìŠ¤íŠ¸(RoPE scaling) A/B í…ŒìŠ¤íŠ¸  
- ë©”íŠ¸ë¦­ Prometheus/Grafana ì™¸ë¶€í™”  
- ì•ŒëŒ ì„ê³„ì¹˜ ì„¤ì •

---

## 17.7 í…ŒìŠ¤íŠ¸ í”Œëœ

- **ì„œë¹™**  
  ë‹¨ìœ„(í”„ë¦¬ì…‹ íŒŒì‹±), í†µí•©(í’€ ë¼ìš°íŒ…/ë°±í”„ë ˆì…”), ë¶€í•˜(hey/k6)

- **LLM**  
  ëª¨ë¸ í•«ìŠ¤ì™‘(ìš”ì²­ ì¤‘ êµì²´), ê³ ì¥ ì£¼ì…(ì—”ë“œí¬ì¸íŠ¸ ê°•ì œ ì‹¤íŒ¨ í›„ ë³µêµ¬)

- **í•™ìŠµ**  
  ì¬í˜„ì„±(seed), ì²´í¬í¬ì¸íŠ¸ ì¬ì‹œì‘, ì†ì‹¤/ì •í™•ë„ ê¸°ì¤€ì¹˜ ê²€ì¦

- **í’ˆì§ˆ**  
  HumanEval/MBPP pass@1/10 ê¸°ì¤€ì„  ì €ì¥  
  ë¦¬ê·¸ë ˆì…˜ ê°ì§€

